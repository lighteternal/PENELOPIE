{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T12:35:03.233368Z",
     "start_time": "2021-02-01T12:35:03.228210Z"
    }
   },
   "source": [
    "### Greek to English translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T15:14:43.495475Z",
     "start_time": "2021-02-01T15:14:37.181970Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from transformers import FSMTTokenizer, FSMTForConditionalGeneration\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "mname = \"lighteternal/SSE-TUC-mt-el-en-cased\"\n",
    "\n",
    "tokenizer = FSMTTokenizer.from_pretrained(mname)\n",
    "model = FSMTForConditionalGeneration.from_pretrained(mname)\n",
    "\n",
    "raw =[]\n",
    "translated =[]\n",
    "\n",
    "#Add your own sentences using the following filepath:\n",
    "with open('data/demo_greek.txt') as file:\n",
    "    for row in file:\n",
    "        encoded = tokenizer.encode(row, return_tensors='pt')\n",
    "        outputs = model.generate(encoded, num_beams=5, num_return_sequences=1, early_stopping=True)\n",
    "        for output in outputs:\n",
    "            raw.append(row)\n",
    "            translated.append(tokenizer.decode(output, skip_special_tokens=True))\n",
    "\n",
    "decoded = pd.DataFrame(list(zip(raw, translated)), \n",
    "               columns =['raw', 'translated']) \n",
    "\n",
    "print(decoded)\n",
    "\n",
    "decoded.to_csv('data/translated.csv')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T12:37:34.776450Z",
     "start_time": "2021-02-01T12:37:34.771141Z"
    }
   },
   "source": [
    "### Information Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T15:59:44.967808Z",
     "start_time": "2021-02-01T15:59:42.073459Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Note: Make sure that you have correctly setup the ClausIE and OpenIE libraries.\n",
    "#Moreover, triple extraction is applied directly to the translated texts.\n",
    "#The extractive summarization and coreference resolution modules are not included in this version.\n",
    "\n",
    "from pyclausie import ClausIE\n",
    "cl = ClausIE.get_instance()\n",
    "\n",
    "from pyopenie import OpenIE5\n",
    "extractor = OpenIE5('http://localhost:9000')\n",
    "\n",
    "from allennlp.predictors.predictor import Predictor\n",
    "predictor1 = Predictor.from_path(\"https://s3-us-west-2.amazonaws.com/allennlp/models/openie-model.2018-08-20.tar.gz\")\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "from itertools import islice\n",
    "import spacy\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "subject =[]\n",
    "predicate = []\n",
    "object = []\n",
    "\n",
    "import nltk\n",
    "\n",
    "df = pd.read_csv('data/translated.csv') \n",
    "df.head()\n",
    "    \n",
    "for index, row in tqdm(df.iterrows()):\n",
    "#for index, row in islice(f.iterrows(), 0, 1):\n",
    "        #print(str(index), file=f, end='\\n', flush=True)\n",
    "\n",
    "    sentence = bytes(row['translated'], 'utf-8').decode('ascii', 'ignore')\n",
    " \n",
    "    print(sentence)\n",
    "\n",
    "    # Clausie triple extraction\n",
    "    try:                \n",
    "        triples = cl.extract_triples([sentence])\n",
    "        for triple in triples:                                        \n",
    "            #print('|-', triple)\n",
    "            subject.append(triple[1])\n",
    "            predicate.append(triple[2])\n",
    "            object.append(triple[3])\n",
    "\n",
    "    except:\n",
    "        print(\"ClausIE failed at extracting a triple from sentence: \", row['translated'])\n",
    "    pass\n",
    "\n",
    "\n",
    "    # OpenIE triple extraction\n",
    "    try:\n",
    "        extractions = extractor.extract(sentence)\n",
    "        for extraction in extractions:\n",
    "            subject.append(extraction['extraction']['arg1']['text'])\n",
    "            predicate.append(extraction['extraction']['rel']['text'])\n",
    "            obj_args =[]\n",
    "            for j in range(len(extraction['extraction']['arg2s'])):\n",
    "                obj_args.append(extraction['extraction']['arg2s'][j]['text'])\n",
    "            object.append(' '.join(obj_args))\n",
    "\n",
    "    except:\n",
    "        print(\"OpenIE failed at extracting a triple from sentence: \", row['translated'])\n",
    "    pass\n",
    "\n",
    "    #  AllenNLP triple extraction\n",
    "    try:                \n",
    "        extracted = predictor1.predict(sentence)\n",
    "        for i in range(len(extracted)):\n",
    "            result = (extracted['verbs'][i]['description'])\n",
    "            subject.append(' '.join(re.findall(r\"\\[ARG0: (.*?)\\]\", result)))\n",
    "            predicate.append(' '.join(re.findall(r\"\\[V: (.*?)\\]\", result)))\n",
    "            object.append(' '.join(re.findall(r\"\\[ARG1:(.*?)\\]\", result)))\n",
    "\n",
    "    except:\n",
    "        print(\"AllenNLP failed at extracting a triple from sentence: \", row['translated'])\n",
    "    pass\n",
    "\n",
    "         \n",
    "    \n",
    "extracted_triples = pd.DataFrame(\n",
    "    {'subject': subject,\n",
    "     'predicate': predicate,\n",
    "     'object': object,\n",
    "    })\n",
    "\n",
    "extracted_triples.replace('', np.nan, inplace=True)\n",
    "extracted_triples = extracted_triples.dropna(how='any') \n",
    "    \n",
    "extracted_triples.to_csv('data/extracted_triples_english.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T15:59:46.123699Z",
     "start_time": "2021-02-01T15:59:46.110125Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extracted triples in English\n",
    "extracted_triples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### English to Greek back-translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T15:59:53.716046Z",
     "start_time": "2021-02-01T15:59:47.699623Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import FSMTTokenizer, FSMTForConditionalGeneration\n",
    "\n",
    "mname = \"lighteternal/SSE-TUC-mt-en-el-cased\"\n",
    "\n",
    "tokenizer = FSMTTokenizer.from_pretrained(mname)\n",
    "model = FSMTForConditionalGeneration.from_pretrained(mname)\n",
    "\n",
    "\n",
    "def translate(text):  \n",
    "    encoded = tokenizer.encode(text, return_tensors='pt')\n",
    "    outputs = model.generate(encoded, num_beams=5, num_return_sequences=1, early_stopping=True)\n",
    "    for output in outputs:\n",
    "        decoded = tokenizer.decode(output, skip_special_tokens=True)\n",
    "    return ''.join(decoded)\n",
    "\n",
    "final = pd.DataFrame(\n",
    "    {'subject': subject,\n",
    "     'predicate': predicate,\n",
    "     'object': object,\n",
    "    })\n",
    "\n",
    "final['subject'] = extracted_triples['subject'].apply(translate)\n",
    "final['predicate'] = extracted_triples['predicate'].apply(translate)\n",
    "final['object'] = extracted_triples['object'].apply(translate)\n",
    "\n",
    "final.replace('', np.nan, inplace=True)\n",
    "final = final.dropna(how='any') \n",
    "final.to_csv('data/final_triples.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T16:00:01.223804Z",
     "start_time": "2021-02-01T16:00:01.215474Z"
    }
   },
   "outputs": [],
   "source": [
    "# Back-translated triples in Greek\n",
    "final"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "penelopie",
   "language": "python",
   "name": "penelopie"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
